---
title: 浏览器中的网络--HTTP/1-HTTP/2-HTTP/3
date: 2020-03-22
description: HTTP/1：HTTP性能优化。HTTP/2：如何提升网络速度？HTTP/3：甩掉TCP、TLS的包袱，构建高效网络。
tags: ['浏览器']
layout: blog-post
---

## HTTP/1：HTTP性能优化

### 缝缝补补的HTTP/1.1

#### 1 改进持久连接
- **HTTP/1.1中增加了持久连接的方法，它的特点是在一个TCP连接上可以传输多个HTTP请求，只要浏览器或者服务器没有明确断开连接，那么该TCP连接会一直保持**。
- 持久连接在HTTP/1.1中是默认开启的，如果不想要采用持久连接，可以在HTTP请求头中加上`Connection: close`。

#### 2 不成熟的HTTP管线化
HTTP/1.1中试图通过管线化的技术来解决`队头阻塞`的问题。HTTP/1.1中的管线化是指将多个HTTP请求整批提交给服务器的技术，虽然可以整批发送请求，不过服务器依然需要根据请求顺序来回复浏览器的请求。

#### 3 提供虚拟主机的支持
HTTP/1.1的请求头中增加了`Host字段`，用来表示当前的域名地址，这样服务器就可以根据不同的Host值做不同的处理。

#### 4 对动态生成的内容提供了完美支持
- 在设计HTTP/1.0时，需要在响应头中设置完整的数据大小，如Content-Length: 901，这样浏览器就可以根据设置的数据大小来接收数据。不过**随着服务器端的技术发展，很多页面的内容都是动态生成的，因此在传输数据之前并不知道最终的数据大小，这就导致了浏览器不知道何时会接收完所有的文件数据**。
- HTTP/1.1通过引入`Chunk transfer机制`来解决这个问题，**服务器会将数据分割成若干个任意大小的数据块，`每个数据块发送时会附上上个数据块的长度`，最后使用一个`零长度的块`作为发送数据完成的标志**。

#### 5 客户端Cookie、安全机制


## HTTP/2：如何提升网络速度？
HTTP/1.1为网络效率做了大量的优化，最核心的有如下三种方式：
- 增加了持久连接；
- **浏览器为`每个域名`最多同时维护6个TCP持久连接**；
- 使用CDN的实现域名分片机制。

### HTTP/1.1的主要问题
**HTTP/1.1对带宽的利用率却并不理想**。主要是由以下三个原因导致的。(带宽是指`每秒最大能发送或者接收的字节数`。每秒能发送的最大字节数称为上行带宽，每秒能够接收的最大字节数称为下行带宽。)
- **第一个原因，TCP的慢启动。**
  - 一旦一个TCP连接建立之后，就进入了发送数据状态，刚开始TCP协议会采用一个非常慢的速度去发送数据，然后慢慢加快发送数据的速度，直到发送数据的速度达到一个理想状态，这个过程称为`慢启动`。
  - 慢启动是TCP为了`减少网络拥塞`的一种策略，我们是没有办法改变的。
  - 之所以说慢启动会带来性能问题，是因为`页面中常用的一些关键资源文件本来就不大`，如HTML文件、CSS文件和JavaScript文件，通常这些文件在TCP连接建立好之后就要发起请求的。
- **第二个原因，同时开启了多条TCP连接，那么这些连接会竞争固定的带宽。**
  - 多条TCP连接之间不能协商让哪些关键资源优先下载，这样有可能影响关键资源的下载速度。
- **第三个原因，HTTP/1.1队头阻塞的问题。**
  - 队头阻塞使得数据`不能并行请求`，所以队头阻塞是很不利于浏览器优化的。

### HTTP/2的多路复用
- HTTP/2的思路是`一个域名只使用一个TCP长连接`来传输数据，这样整个页面资源的下载过程只需要一次慢启动，同时也避免了多个TCP连接竞争带宽所带来的问题。
- HTTP/2需要`实现资源的并行请求(消除队头阻塞问题)`，也就是任何时候都可以将请求发送给服务器，而并不需要等待其他请求的完成，然后服务器也可以随时返回处理好的请求资源给浏览器。

#### 多路复用的实现
![HTTP2协议栈](../assets/浏览器/0068_HTTP2协议栈.png)

HTTP/2添加了一个**二进制分帧层**，请求过程：
- 首先，`浏览器准备好请求数据`，包括了请求行、请求头等信息，如果是POST方法，那么还要有请求体。
- 这些`数据`经过二进制分帧层处理之后，会被`转换为一个个带有请求ID编号的帧`，通过协议栈将这些帧发送给服务器。
- 服务器接收到所有帧之后，会将所有相同ID的帧合并为一条完整的请求信息。
- 然后服务器处理该条请求，并将处理的响应行、响应头和响应体分别发送至二进制分帧层。
- 同样，二进制分帧层会将这些响应数据转换为一个个带有请求ID编号的帧，经过协议栈发送给浏览器。
- 浏览器接收到响应帧之后，会根据ID编号将帧的数据提交给对应的请求。

### HTTP/2其他特性
#### 1 可以设置请求的优先级
HTTP/2提供了请求优先级，可以在发送请求时，标上该请求的优先级，这样服务器接收到请求之后，会优先处理优先级高的请求。

#### 2 服务器推送
HTTP/2还可以直接将数据提前推送到浏览器。比如，请求一个HTML文件，里面又引入了CSS文件和JavaScript文件，当服务器接收到HTML请求后，附带把CSS和JS文件一起返回给浏览器。

#### 3 头部压缩
**HTTP/2对请求头和响应头进行了压缩。**


## HTTP/3：甩掉TCP、TLS的包袱，构建高效网络

### TCP的队头阻塞
**在TCP传输过程中，由于单个数据包的丢失而造成的阻塞称为TCP上的`队头阻塞`。**
![TCP丢包](../assets/浏览器/0069_TCP丢包.png)

**那队头阻塞是怎么影响HTTP/2传输的呢？**
![HTTP2多路复用](../assets/浏览器/0070_HTTP2多路复用.png)
- 在HTTP/2中，多个请求是跑在一个TCP管道中的，如果其中任意一路数据流中出现了丢包的情况，那么就会阻塞该TCP连接中的所有请求。
- 所以**随着丢包率的增加，HTTP/2的传输效率也会越来越差**。

### TCP建立连接的延时
从浏览器发送一个数据包到服务器，再从服务器返回数据包到浏览器的整个往返时间称为`RTT(网络延迟，Round Trip Time)`。
- 在建立TCP连接的时候，需要和服务器进行三次握手来确认连接成功，也就是说需要在消耗完1.5个RTT之后才能进行数据传输。
- 进行TLS连接，TLS有两个版本——TLS1.2和TLS1.3，每个版本建立连接所花的时间不同，大致是需要1～2个RTT。

### TCP协议僵化
- 中间设备的僵化。包括了路由器、防火墙、NAT、交换机等，它们通常依赖一些很少升级的软件，这些软件使用了大量的TCP特性，这些功能被设置之后就很少更新了。
- **操作系统也是导致TCP协议僵化的另外一个原因**。因为TCP协议都是通过`操作系统内核`来实现的，应用程序只能使用不能修改。

### QUIC协议
- HTTP/2存在一些比较严重的与TCP协议相关的缺陷，但由于TCP协议僵化，我们几乎不可能通过修改TCP协议自身来解决这些问题，那么解决问题的思路是绕过TCP协议，发明一个TCP和UDP之外的新的传输协议。
- 但是这也面临着和修改TCP一样的挑战，因为中间设备的僵化，这些设备只认TCP和UDP，如果采用了新的协议，新协议在这些设备同样不被很好地支持。
- 因此，**HTTP/3选择了一个折衷的方法——UDP协议，`基于UDP实现了类似于TCP的多路数据流、传输可靠性等功能`，我们把这套功能称为`QUIC协议`**。

HTTP2和HTTP3协议栈对比：
![HTTP2和HTTP3协议栈](../assets/浏览器/0071_HTTP2和HTTP3协议栈.png)

HTTP/3中的QUIC协议集合了以下几点功能：
- **实现了类似TCP的流量控制、传输可靠性的功能。**虽然UDP不提供可靠性的传输，但QUIC在UDP的基础之上增加了一层来保证数据可靠性传输。它提供了数据包重传、拥塞控制以及其他一些TCP中存在的特性。
- **集成了TLS加密功能。**目前QUIC使用的是TLS1.3，相较于早期版本TLS1.3有更多的优点，其中最重要的一点是`减少了握手所花费的RTT个数`。
- **实现了HTTP/2中的多路复用功能。**和TCP不同，QUIC实现了`在同一物理连接上可以有多个独立的逻辑数据流`（如下图）。实现了数据流的单独传输，就解决了TCP中队头阻塞的问题。
![QUIC协议的多路复用](../assets/浏览器/0072_QUIC协议的多路复用.png)
- **实现了快速握手功能。**由于QUIC是基于UDP的，所以QUIC可以实现使用0-RTT或者1-RTT来建立连接，这意味着QUIC可以用最快的速度来发送和接收数据，这样可以大大提升首次打开页面的速度。

### HTTP/3的挑战
- 第一，从目前的情况来看，`服务器和浏览器`端都没有对HTTP/3提供比较完整的支持。
- 第二，`部署HTTP/3`也存在着非常大的问题。因为系统内核对UDP的优化远远没有达到TCP的优化程度，这也是阻碍QUIC的一个重要原因。
- 第三，`中间设备僵化`的问题。这些设备对UDP的优化程度远远低于TCP，据统计使用QUIC协议时，大约有3%～7%的丢包率。
